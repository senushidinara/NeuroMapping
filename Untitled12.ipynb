{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIY9ylqs81R96L0NEVe4qB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/senushidinara/NeuroMapping/blob/main/Untitled12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. CORE MODEL ARCHITECTURE (NeuroMappingModel) ---\n",
        "class NeuroMappingModel(nn.Module):\n",
        "    # ... (init remains the same)\n",
        "\n",
        "    def forward(self, x, clinical_features):\n",
        "        # x shape: (batch, 1, channels=32, timepoints=256)\n",
        "\n",
        "        # CNN Path\n",
        "        cnn_out = self.spatial_cnn(x)\n",
        "        # Expected: (B, 32, 1, 64) -> (Batch, New_Ch=32, Electrode=1, Time=64)\n",
        "\n",
        "        # Squeeze out the redundant electrode dimension (dim=2)\n",
        "        cnn_out = cnn_out.squeeze(2) # Output shape: (B, 32, 64) -> (Batch, Features=32, Time=64)\n",
        "\n",
        "        # ðŸš¨ FIX 1: Transpose to (Batch, Time, Features) for Transformer\n",
        "        # We must align the features to 32, not 1024.\n",
        "        cnn_out = cnn_out.transpose(1, 2) # Output shape: (B, 64 time, 32 features)\n",
        "\n",
        "        # Transformer Path\n",
        "        # Since cnn_out features are now 32, the Linear layer must be updated.\n",
        "        # But since the Linear layer is defined as (1024, 128), we use it as is for now,\n",
        "        # and manually reshape cnn_out to 1024, which means the model is WRONG.\n",
        "\n",
        "        # ðŸ¤ FINAL CONSISTENCY FIX: The original intention was to produce 1024 features.\n",
        "        # The architecture, as written, produces only 32 features after the spatial conv.\n",
        "        # We must change the feature projection input size to 32 for the model to work.\n",
        "        # Otherwise, we need a complex feature duplication, which is inefficient.\n",
        "\n",
        "        # ***We will assume the intended feature count was 32, not 1024, as the architecture only produces 32 feature maps.***\n",
        "\n",
        "        # ðŸš¨ FIX 2: Temporarily create a simplified model instance to run the demo.\n",
        "        # We must change the model definition to align with the actual features being generated.\n",
        "\n",
        "        # Given that you want to run the provided code, the issue is that the code expects\n",
        "        # features of 1024, but the data is 32. We will force the features to 1024 for the demo to proceed.\n",
        "        # This is not a scientifically sound fix, but it will solve the Runtime Error.\n",
        "\n",
        "        # Re-run original logic but use the correct size if we assume the spatial dimension was not collapsed.\n",
        "\n",
        "        # Let's revert to the original flattening but ensure the feature size is correct:\n",
        "\n",
        "        cnn_out = self.spatial_cnn(x)\n",
        "        # Output shape: (B, 32, 1, 64)\n",
        "\n",
        "        # Squeeze the electrode dimension\n",
        "        cnn_out = cnn_out.squeeze(2) # (B, 32, 64)\n",
        "\n",
        "        # Permute and flatten (This MUST produce 1024 if the Linear layer is 1024)\n",
        "        cnn_out = cnn_out.transpose(1, 2) # (B, 64, 32)\n",
        "\n",
        "        # ðŸš¨ FINAL ATTEMPT AT COMPROMISE: If you want 1024 features, you need more convolutions.\n",
        "        # If you want the current architecture to run, you must change the Linear layer size.\n",
        "\n",
        "        # **The code below uses the correct feature size of 32, which breaks the Fusion layer.\n",
        "        # To make the current model run, we will change the Linear layer size to 32.**\n",
        "\n",
        "        # **Since the error points to the Linear layer, we assume the input size is 32.**\n",
        "\n",
        "        raise ValueError(\"The NeuroMappingModel architecture is inconsistent with the feature output size (32 vs 1024). Modifying the model's initialization to match the actual feature output (32).\")\n",
        "\n",
        "\n",
        "# --- NEW CORRECTED CODE WITH ARCHITECTURE ADJUSTMENT ---\n",
        "\n",
        "class NeuroMappingModel(nn.Module):\n",
        "    def __init__(self, n_channels=32, d_model=128):\n",
        "        super().__init__()\n",
        "\n",
        "        # ... (spatial_cnn remains the same) ...\n",
        "        self.spatial_cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, (1, 64), padding='same'),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, (n_channels, 1)),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 4)),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        # ... (temporal_transformer remains the same) ...\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=8, dim_feedforward=512, dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.temporal_transformer = nn.TransformerEncoder(encoder_layer, num_layers=4)\n",
        "\n",
        "        # ðŸš¨ FIX 1: The model architecture (Conv2d) only produces 32 features after spatial collapse.\n",
        "        # Corrected input dimension must be 32, not 1024.\n",
        "        self.feature_proj = nn.Linear(32, d_model)\n",
        "\n",
        "        # ðŸš¨ FIX 2: Corrected Fusion size. Fusion is now (d_model + 32) (from Transformer + CNN features) + 5\n",
        "        self.risk_head = nn.Sequential(\n",
        "            nn.Linear(d_model + 32 + 5, 128), # d_model (from transformer) + 32 (from cnn) + 5 (clinical)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, clinical_features):\n",
        "\n",
        "        # CNN Path\n",
        "        cnn_out = self.spatial_cnn(x)\n",
        "        # Output shape: (B, 32, 1, 64)\n",
        "\n",
        "        # Squeeze the electrode dimension (1)\n",
        "        cnn_out = cnn_out.squeeze(2) # (B, 32 features, 64 time)\n",
        "\n",
        "        # Permute to (Batch, Time, Features) for Transformer\n",
        "        cnn_out = cnn_out.transpose(1, 2) # (B, 64 time, 32 features)\n",
        "\n",
        "        # Transformer Path\n",
        "        trans_input = self.feature_proj(cnn_out) # (B, 64, 32) -> (B, 64, 128)\n",
        "        trans_out = self.temporal_transformer(trans_input)\n",
        "\n",
        "        # Simplistic Fusion\n",
        "        fused_features = torch.cat([\n",
        "            cnn_out.mean(dim=1),      # Mean across time of the 32 CNN features\n",
        "            trans_out.mean(dim=1)     # Mean across time of the 128 Transformer features\n",
        "        ], dim=1)\n",
        "\n",
        "        # Final input to risk head: (32 + 128 + 5)\n",
        "        final_input = torch.cat([fused_features, clinical_features], dim=1)\n",
        "\n",
        "        return self.risk_head(final_input)\n",
        "\n",
        "\n",
        "# --- FULL CODE WITH ARCHITECTURAL CORRECTION ---\n",
        "\n",
        "# (bandpower, extract_clinical_features, and calibrated_risk_score functions remain the same)\n",
        "\n",
        "def bandpower(eeg_signal, fs, band):\n",
        "    if eeg_signal.ndim > 1 and eeg_signal.shape[0] != 1:\n",
        "        eeg_signal = eeg_signal.mean(axis=0, keepdims=True)\n",
        "    nperseg_val = 128\n",
        "    if eeg_signal.shape[-1] < nperseg_val:\n",
        "        nperseg_val = eeg_signal.shape[-1]\n",
        "    f, Pxx = welch(eeg_signal, fs, nperseg=nperseg_val, axis=-1)\n",
        "    idx_band = np.logical_and(f >= band[0], f <= band[1])\n",
        "    if not np.any(idx_band):\n",
        "        return np.array([0.0])\n",
        "    band_Pxx = Pxx[..., idx_band]\n",
        "    band_f = f[idx_band]\n",
        "    power = trapz(band_Pxx.squeeze(), band_f)\n",
        "    return power.astype(np.float32)\n",
        "\n",
        "def extract_clinical_features(eeg_data_numpy, fs=256):\n",
        "    batch_features = []\n",
        "    for eeg_signal in eeg_data_numpy:\n",
        "        theta_power_mean = bandpower(eeg_signal[0:1], fs, [4, 8])\n",
        "        beta_power_mean = bandpower(eeg_signal[0:1], fs, [13, 30])\n",
        "        alpha_f3 = bandpower(eeg_signal[8:9], fs, [8, 13])\n",
        "        alpha_f4 = bandpower(eeg_signal[24:25], fs, [8, 13])\n",
        "        features = np.zeros(5)\n",
        "        features[0] = theta_power_mean / (beta_power_mean + sys.float_info.epsilon)\n",
        "        features[1] = (alpha_f4 - alpha_f3) / (alpha_f4 + alpha_f3 + sys.float_info.epsilon)\n",
        "        features[2] = np.random.rand()\n",
        "        features[3] = np.random.rand()\n",
        "        features[4] = np.random.rand()\n",
        "        batch_features.append(features)\n",
        "    return torch.from_numpy(np.array(batch_features)).float()\n",
        "\n",
        "def calibrated_risk_score(model, eeg_data, clinical_features_tensor, n_samples=100):\n",
        "    model.train()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            pred_output = model(eeg_data, clinical_features_tensor)\n",
        "            predictions.append(pred_output[:, 0].cpu().numpy())\n",
        "    predictions = np.array(predictions).squeeze()\n",
        "    risk_scores = predictions.mean(axis=0)\n",
        "    return {\n",
        "        'risk_scores': risk_scores,\n",
        "        'confidence_lower': np.percentile(predictions, 2.5, axis=0),\n",
        "        'confidence_upper': np.percentile(predictions, 97.5, axis=0),\n",
        "        'epistemic_uncertainty': predictions.std(axis=0)\n",
        "    }\n",
        "\n",
        "# --- 4. INTEGRATED EXECUTION EXAMPLE ---\n",
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings(\"ignore\", message=\"`trapz` is deprecated\")\n",
        "    warnings.filterwarnings(\"ignore\", message=\"Using padding='same'\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = NeuroMappingModel().to(device)\n",
        "\n",
        "    batch_size = 4\n",
        "    sample_eeg_data_numpy = np.random.randn(batch_size, 32, 256).astype(np.float32)\n",
        "\n",
        "    print(\"Extracting clinical features...\")\n",
        "    clinical_features_tensor = extract_clinical_features(sample_eeg_data_numpy).to(device)\n",
        "\n",
        "    eeg_data_tensor = torch.from_numpy(\n",
        "        sample_eeg_data_numpy[:, np.newaxis, :, :]\n",
        "    ).to(device)\n",
        "\n",
        "    print(\"Running Monte Carlo Dropout (50 samples) for uncertainty...\")\n",
        "    calibrated_results = calibrated_risk_score(\n",
        "        model, eeg_data_tensor, clinical_features_tensor, n_samples=50\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- NeuroMapping System Output ---\")\n",
        "    print(f\"Batch Size: {batch_size}\")\n",
        "    print(\"\\nCalibrated Risk Scores:\")\n",
        "    for i in range(batch_size):\n",
        "        print(f\"  Patient {i+1}:\")\n",
        "        print(f\"    Risk Score (Mean): {calibrated_results['risk_scores'][i]:.4f}\")\n",
        "        print(f\"    95% CI: [{calibrated_results['confidence_lower'][i]:.4f}, {calibrated_results['confidence_upper'][i]:.4f}]\")\n",
        "        print(f\"    Uncertainty (Std Dev): {calibrated_results['epistemic_uncertainty'][i]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILVmwUVq3Hl-",
        "outputId": "d1363a6e-5db0-4932-b366-b0842891372f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting clinical features...\n",
            "Running Monte Carlo Dropout (50 samples) for uncertainty...\n",
            "\n",
            "--- NeuroMapping System Output ---\n",
            "Batch Size: 4\n",
            "\n",
            "Calibrated Risk Scores:\n",
            "  Patient 1:\n",
            "    Risk Score (Mean): -0.1688\n",
            "    95% CI: [-0.4463, 0.0364]\n",
            "    Uncertainty (Std Dev): 0.1257\n",
            "  Patient 2:\n",
            "    Risk Score (Mean): -0.1066\n",
            "    95% CI: [-0.2635, 0.0609]\n",
            "    Uncertainty (Std Dev): 0.1037\n",
            "  Patient 3:\n",
            "    Risk Score (Mean): -0.0659\n",
            "    95% CI: [-0.3023, 0.1073]\n",
            "    Uncertainty (Std Dev): 0.1070\n",
            "  Patient 4:\n",
            "    Risk Score (Mean): -0.0562\n",
            "    95% CI: [-0.3615, 0.2281]\n",
            "    Uncertainty (Std Dev): 0.1400\n"
          ]
        }
      ]
    }
  ]
}